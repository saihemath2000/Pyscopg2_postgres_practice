{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5556f0-d189-462c-b528-1118d1706ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n",
      "Script completed in 26.01 seconds\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import pool\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from psycopg2.extras import execute_batch\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "DB_NAME = \"next_gen\"\n",
    "DB_USER = \"sde\"\n",
    "DB_PASS = \"sde\"\n",
    "DB_HOST = \"salesiqgen2.cygagau4oro0.us-west-2.rds.amazonaws.com\"\n",
    "DB_PORT = \"5432\"\n",
    "\n",
    "\n",
    "try:\n",
    "    # Create a connection pool\n",
    "    connection_pool = psycopg2.pool.ThreadedConnectionPool(1, 10, database=DB_NAME, user=DB_USER, password=DB_PASS, host=DB_HOST, port=DB_PORT)\n",
    "    if connection_pool:\n",
    "        print(\"Connection pool created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection pool creation failed: {e}\")\n",
    "\n",
    "# Function to find max level\n",
    "def find_max_level(cur):\n",
    "    max_level = 0\n",
    "    level = 1\n",
    "    while True:\n",
    "        code_column = f\"level{level}_code\"\n",
    "        cur.execute(f\"SELECT COUNT(*) FROM qa_mergetest5_position_geo_temp WHERE {code_column} IS NOT NULL\")\n",
    "        count = cur.fetchone()[0]\n",
    "        if count == 0:\n",
    "            break\n",
    "        max_level = level\n",
    "        level += 1\n",
    "    return max_level\n",
    "\n",
    "try:\n",
    "    # Get a connection from the pool\n",
    "    conn = connection_pool.getconn()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    max_level = find_max_level(cur)\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT DISTINCT jsonb_object_keys(CAST(metric_data AS jsonb)) AS metric_key\n",
    "        FROM qa_mergetest5_position_geo_temp\n",
    "    \"\"\")\n",
    "    metric_keys = [row[0] for row in cur.fetchall()]\n",
    "\n",
    "    # Prepare metric data items for the SQL query\n",
    "    metric_data_items = ', '.join([f\"'{metric_key}', SUM(COALESCE((metric_data::jsonb->>'{metric_key}')::float, 0))\" for metric_key in metric_keys])\n",
    "\n",
    "    # Function to execute a single query\n",
    "    def execute_query(query):\n",
    "        conn = connection_pool.getconn()\n",
    "        try:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(query)\n",
    "                return cur.fetchall()\n",
    "        finally:\n",
    "            connection_pool.putconn(conn)\n",
    "\n",
    "    queries = []\n",
    "    for level in range(1, max_level + 1):\n",
    "        code_column = f\"level{level}_code\"\n",
    "        code_name = f\"level{level}_name\"\n",
    "        queries.append(f\"\"\"\n",
    "            SELECT \n",
    "                {code_column} AS code,\n",
    "                {code_name} AS name,\n",
    "                {level} AS level, \n",
    "                jsonb_build_object(\n",
    "                    {metric_data_items}\n",
    "                ) AS metric_data,\n",
    "                ST_Union(shape) AS shape\n",
    "            FROM qa_mergetest5_position_geo_temp\n",
    "            GROUP BY {code_column}, {code_name}\n",
    "        \"\"\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        results = list(executor.map(execute_query, queries))\n",
    "\n",
    "    # Flatten the results\n",
    "    results = [item for sublist in results for item in sublist]\n",
    "\n",
    "    columns = [\"code\", \"name\", \"level\", \"metric_data\", \"shape\"]\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "    df[\"metric_data\"] = df[\"metric_data\"].apply(lambda x: json.dumps(x))\n",
    "\n",
    "    # Convert DataFrame to list of tuples\n",
    "    records = df.to_records(index=False)\n",
    "    records_list = [(r[0], r[1], int(r[2]), r[3], r[4]) for r in records]\n",
    "\n",
    "    # Define the insert query\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO hg_positions (code, name, level, metric_data, shape)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    # Bulk insert using execute_batch\n",
    "    execute_batch(cur, insert_query, records_list)\n",
    "\n",
    "    # Commit the transaction\n",
    "    conn.commit()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and return the connection to the pool\n",
    "    cur.close()\n",
    "    connection_pool.putconn(conn)\n",
    "\n",
    "    # Close all connections in the pool\n",
    "    connection_pool.closeall()\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Script completed in {elapsed_time:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
